{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.distance import cdist\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ft_data(file_path, force_threshold=0.3):\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert timestamp to datetime if needed\n",
    "    df['timestamp'] = pd.to_numeric(df['timestamp'])\n",
    "    df['time_relative'] = df['timestamp'] - df['timestamp'].min()\n",
    "    \n",
    "    # Calculate force magnitude\n",
    "    df['force_magnitude'] = np.sqrt(df['force_x']**2 + df['force_y']**2 + df['force_z']**2)\n",
    "    \n",
    "    # Filter based on threshold\n",
    "    df_filtered = df[df['force_magnitude'] >= force_threshold]\n",
    "    \n",
    "    print(f\"Original samples: {len(df)}\")\n",
    "    print(f\"Filtered samples: {len(df_filtered)}\")\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Assuming the file is in the ../data/raw directory relative to this notebook\n",
    "data_path = Path('../../data/raw/ft_data_simulated.csv')  # Adjust path as needed\n",
    "df = load_ft_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"Data Overview:\")\n",
    "print(f\"Number of recordings: {len(df)}\")\n",
    "print(f\"Time span: {df['time_relative'].max():.2f} seconds\")\n",
    "print(\"\\nContact point statistics:\")\n",
    "print(df[['contact_x', 'contact_y']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trajectory(df, num_interpolation_points=1000):\n",
    "    \n",
    "    # Get timestamps for interpolation\n",
    "    times = df['timestamp'].values\n",
    "    x = df['contact_x'].values\n",
    "    y = df['contact_y'].values\n",
    "    \n",
    "    # Create interpolation functions\n",
    "    f_x = interp1d(times, x, kind='cubic')\n",
    "    f_y = interp1d(times, y, kind='cubic')\n",
    "    \n",
    "    # Create new time points for smooth interpolation\n",
    "    t_new = np.linspace(times.min(), times.max(), num_interpolation_points)\n",
    "    \n",
    "    # Generate interpolated points\n",
    "    x_interp = f_x(t_new)\n",
    "    y_interp = f_y(t_new)\n",
    "    \n",
    "    return x_interp, y_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_interp, y_interp = create_trajectory(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of contact points\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(x_interp, y_interp, color='red', alpha=0.8)\n",
    "plt.scatter(df['contact_x'], df['contact_y'], alpha=0.5, c=df['time_relative'], cmap='viridis')\n",
    "plt.colorbar(label='Time (seconds)')\n",
    "plt.xlabel('Contact X Position')\n",
    "plt.ylabel('Contact Y Position')\n",
    "plt.title('Contact Points Trajectory')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grid(x_coords, y_coords, forces=None, grid_size=28, line_thickness=1):\n",
    "\n",
    "    # Normalize coordinates to [0, grid_size-1]\n",
    "    x_min, x_max = x_coords.min(), x_coords.max()\n",
    "    y_min, y_max = y_coords.min(), y_coords.max()\n",
    "\n",
    "    # Add small padding to ensure points at edges are included\n",
    "    x_padding = (x_max - x_min) * 0.1\n",
    "    y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "    x_min -= x_padding\n",
    "    x_max += x_padding\n",
    "    y_min -= y_padding\n",
    "    y_max += y_padding\n",
    "    \n",
    "    x_normalized = ((x_coords - x_min) / (x_max - x_min) * (grid_size - 1))\n",
    "    y_normalized = ((y_coords - y_min) / (y_max - y_min) * (grid_size - 1))\n",
    "    \n",
    "    # Create empty grid\n",
    "    grid = np.zeros((grid_size, grid_size))\n",
    "    \n",
    "    # Convert coordinates to integer indices\n",
    "    x_indices = x_normalized.round().astype(int)\n",
    "    y_indices = y_normalized.round().astype(int)\n",
    "    \n",
    "    # Draw trajectory with thickness\n",
    "    for i in range(len(x_indices)-1):\n",
    "        # Get current and next point\n",
    "        x1, y1 = x_indices[i], y_indices[i]\n",
    "        x2, y2 = x_indices[i+1], y_indices[i+1]\n",
    "        \n",
    "        # Interpolate points between current and next point\n",
    "        num_steps = max(abs(x2-x1), abs(y2-y1)) * 2\n",
    "        if num_steps > 0:\n",
    "            xs = np.linspace(x1, x2, num_steps+1)\n",
    "            ys = np.linspace(y1, y2, num_steps+1)\n",
    "            \n",
    "            # Draw thick line by filling neighboring pixels\n",
    "            for x, y in zip(xs, ys):\n",
    "                x, y = int(round(x)), int(round(y))\n",
    "                for dx in range(-line_thickness, line_thickness+1):\n",
    "                    for dy in range(-line_thickness, line_thickness+1):\n",
    "                        if 0 <= x+dx < grid_size and 0 <= y+dy < grid_size:\n",
    "                            grid[y+dy, x+dx] = 1\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grid with different line thicknesses\n",
    "grids = {\n",
    "    'thin': convert_to_grid(x_interp, y_interp, line_thickness=0),\n",
    "    'medium': convert_to_grid(x_interp, y_interp, line_thickness=1),\n",
    "    'thick': convert_to_grid(x_interp, y_interp, line_thickness=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# Original points and interpolated trajectory\n",
    "plt.subplot(141)\n",
    "plt.scatter(df['contact_x'], df['contact_y'], \n",
    "           c=df['force_magnitude'], cmap='viridis', alpha=0.6, label='Original Points')\n",
    "plt.plot(x_interp, y_interp, 'r-', alpha=0.5, label='Interpolated Trajectory')\n",
    "plt.colorbar(label='Force Magnitude')\n",
    "plt.title('Points and Trajectory')\n",
    "plt.legend()\n",
    "\n",
    "# Show different line thicknesses\n",
    "for i, (thickness, grid) in enumerate(grids.items(), 2):\n",
    "    plt.subplot(1, 4, i)\n",
    "    plt.imshow(grid, cmap='gray_r')\n",
    "    plt.title(f'Grid ({thickness} line)')\n",
    "    plt.axis('on')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print grid statistics\n",
    "for thickness, grid in grids.items():\n",
    "    print(f\"\\nGrid Statistics ({thickness} line):\")\n",
    "    print(f\"Non-zero cells: {np.count_nonzero(grid)} out of {grid.size}\")\n",
    "    print(f\"Coverage: {np.count_nonzero(grid)/grid.size*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('../../model/mnist_cnn.pth'))\n",
    "model.eval()\n",
    "# If CUDA is available, move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model moved to device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class TrajectoryRecognizer:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"\n",
    "        Initialize the recognizer with a trained model\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): Path to the trained PyTorch model\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = Net()\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Model moved to device: {self.device}\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Define preprocessing transforms to match MNIST format\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))  # MNIST normalization values\n",
    "        ])\n",
    "    \n",
    "    def preprocess_trajectory(self, df, force_threshold=0.5, num_interpolation_points=1000, line_thickness=1):\n",
    "        \"\"\"\n",
    "        Preprocess trajectory data into MNIST-like format\n",
    "        \"\"\"\n",
    "        # Filter by force magnitude\n",
    "        df['force_magnitude'] = np.sqrt(df['force_x']**2 + df['force_y']**2 + df['force_z']**2)\n",
    "        df_filtered = df[df['force_magnitude'] >= force_threshold].copy()\n",
    "        \n",
    "        if len(df_filtered) == 0:\n",
    "            raise ValueError(\"No points remain after force threshold filtering\")\n",
    "            \n",
    "        # Interpolate trajectory\n",
    "        times = df_filtered['timestamp'].values\n",
    "        x = df_filtered['contact_x'].values\n",
    "        y = df_filtered['contact_y'].values\n",
    "        \n",
    "        t_new = np.linspace(times.min(), times.max(), num_interpolation_points)\n",
    "        x_interp = np.interp(t_new, times, x)\n",
    "        y_interp = np.interp(t_new, times, y)\n",
    "        \n",
    "        # Convert to grid\n",
    "        grid = self.trajectory_to_grid(x_interp, y_interp, line_thickness)\n",
    "        \n",
    "        # Convert to tensor format\n",
    "        tensor_image = self.transform(grid.astype(np.float32))\n",
    "        tensor_image = tensor_image.to(self.device)\n",
    "        \n",
    "        # Return all intermediate results for visualization\n",
    "        preprocessing_data = {\n",
    "            'df_filtered': df_filtered,\n",
    "            'x_interp': x_interp,\n",
    "            'y_interp': y_interp,\n",
    "            't_new': t_new,\n",
    "            'times': times\n",
    "        }\n",
    "        \n",
    "        return grid, tensor_image, preprocessing_data\n",
    "    \n",
    "    def trajectory_to_grid(self, x_coords, y_coords, line_thickness=1, grid_size=28):\n",
    "        \"\"\"\n",
    "        Convert trajectory coordinates to grid format\n",
    "        \"\"\"\n",
    "        # Normalize coordinates with padding\n",
    "        x_min, x_max = x_coords.min(), x_coords.max()\n",
    "        y_min, y_max = y_coords.min(), y_coords.max()\n",
    "\n",
    "        # Add small padding to ensure points at edges are included\n",
    "        x_padding = (x_max - x_min) * 0.1\n",
    "        y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "        x_min -= x_padding\n",
    "        x_max += x_padding\n",
    "        y_min -= y_padding\n",
    "        y_max += y_padding\n",
    "        \n",
    "        x_normalized = ((x_coords - x_min) / (x_max - x_min) * (grid_size - 1))\n",
    "        y_normalized = ((y_coords - y_min) / (y_max - y_min) * (grid_size - 1))\n",
    "        \n",
    "        grid = np.zeros((grid_size, grid_size))\n",
    "        \n",
    "        # Draw trajectory with thickness\n",
    "        for i in range(len(x_normalized)-1):\n",
    "            x1, y1 = int(round(x_normalized[i])), int(round(y_normalized[i]))\n",
    "            x2, y2 = int(round(x_normalized[i+1])), int(round(y_normalized[i+1]))\n",
    "            \n",
    "            # Interpolate between points\n",
    "            num_steps = max(abs(x2-x1), abs(y2-y1)) * 2\n",
    "            if num_steps > 0:\n",
    "                xs = np.linspace(x1, x2, num_steps+1)\n",
    "                ys = np.linspace(y1, y2, num_steps+1)\n",
    "                \n",
    "                for x, y in zip(xs, ys):\n",
    "                    x, y = int(round(x)), int(round(y))\n",
    "                    for dx in range(-line_thickness, line_thickness+1):\n",
    "                        for dy in range(-line_thickness, line_thickness+1):\n",
    "                            if 0 <= x+dx < grid_size and 0 <= y+dy < grid_size:\n",
    "                                grid[y+dy, x+dx] = 1\n",
    "        \n",
    "        return grid\n",
    "    \n",
    "    def predict(self, tensor_image):\n",
    "        \"\"\"\n",
    "        Make prediction using the model\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Add batch dimension\n",
    "            input_tensor = tensor_image.unsqueeze(0)\n",
    "            \n",
    "            # Get model prediction\n",
    "            output = self.model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            predicted_class = output.argmax(dim=1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "            \n",
    "            # Get top-3 predictions\n",
    "            top3_prob, top3_indices = torch.topk(probabilities, 3)\n",
    "            top3_predictions = [(idx.item(), prob.item()) \n",
    "                              for idx, prob in zip(top3_indices[0], top3_prob[0])]\n",
    "            \n",
    "        return predicted_class, confidence, top3_predictions\n",
    "\n",
    "    def visualize_complete_process(self, df_original, grid, preprocessing_data, \n",
    "                                 predicted_class, confidence, top3_predictions):\n",
    "        \"\"\"\n",
    "        Visualize the complete preprocessing and recognition process\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # 1. Original data with force magnitude\n",
    "        ax1 = plt.subplot(231)\n",
    "        scatter = ax1.scatter(df_original['contact_x'], df_original['contact_y'], \n",
    "                            c=df_original['force_magnitude'], cmap='viridis', alpha=0.6)\n",
    "        plt.colorbar(scatter, ax=ax1, label='Force Magnitude')\n",
    "        ax1.set_title('Original Data')\n",
    "        ax1.set_xlabel('X Position')\n",
    "        ax1.set_ylabel('Y Position')\n",
    "        \n",
    "        # 2. Filtered data\n",
    "        ax2 = plt.subplot(232)\n",
    "        df_filtered = preprocessing_data['df_filtered']\n",
    "        scatter = ax2.scatter(df_filtered['contact_x'], df_filtered['contact_y'],\n",
    "                            c=df_filtered['force_magnitude'], cmap='viridis', alpha=0.6)\n",
    "        plt.colorbar(scatter, ax=ax2, label='Force Magnitude')\n",
    "        ax2.set_title('Filtered Data')\n",
    "        ax2.set_xlabel('X Position')\n",
    "        ax2.set_ylabel('Y Position')\n",
    "        \n",
    "        # 3. Interpolated trajectory\n",
    "        ax3 = plt.subplot(233)\n",
    "        ax3.plot(preprocessing_data['x_interp'], preprocessing_data['y_interp'], \n",
    "                'b-', label='Interpolated', alpha=0.7)\n",
    "        ax3.scatter(df_filtered['contact_x'], df_filtered['contact_y'],\n",
    "                   c='red', alpha=0.4, s=30, label='Original Points')\n",
    "        ax3.set_title('Interpolated Trajectory')\n",
    "        ax3.set_xlabel('X Position')\n",
    "        ax3.set_ylabel('Y Position')\n",
    "        ax3.legend()\n",
    "        \n",
    "        # 4. Final grid\n",
    "        ax4 = plt.subplot(234)\n",
    "        ax4.imshow(grid, cmap='gray_r')\n",
    "        ax4.set_title('Grid Representation')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Prediction results\n",
    "        ax5 = plt.subplot(235)\n",
    "        ax5.axis('off')\n",
    "        prediction_text = [\n",
    "            f'Predicted Digit: {predicted_class}',\n",
    "            f'Confidence: {confidence:.2%}',\n",
    "            '\\nTop 3 Predictions:'\n",
    "        ]\n",
    "        for digit, prob in top3_predictions:\n",
    "            prediction_text.append(f'{digit}: {prob:.2%}')\n",
    "        \n",
    "        ax5.text(0.1, 0.6, '\\n'.join(prediction_text), fontsize=12)\n",
    "        ax5.set_title('Recognition Results')\n",
    "        \n",
    "        # 6. Time series plot\n",
    "        ax6 = plt.subplot(236)\n",
    "        times = preprocessing_data['times']\n",
    "        t_new = preprocessing_data['t_new']\n",
    "        ax6.plot(t_new - t_new[0], preprocessing_data['x_interp'], \n",
    "                'b-', label='X interpolated', alpha=0.7)\n",
    "        ax6.plot(t_new - t_new[0], preprocessing_data['y_interp'], \n",
    "                'r-', label='Y interpolated', alpha=0.7)\n",
    "        ax6.scatter(times - times[0], df_filtered['contact_x'], \n",
    "                   c='blue', alpha=0.4, s=30, label='X original')\n",
    "        ax6.scatter(times - times[0], df_filtered['contact_y'], \n",
    "                   c='red', alpha=0.4, s=30, label='Y original')\n",
    "        ax6.set_title('Position vs Time')\n",
    "        ax6.set_xlabel('Time (s)')\n",
    "        ax6.set_ylabel('Position')\n",
    "        ax6.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def recognize_trajectory(data_file, model_path):\n",
    "    \"\"\"\n",
    "    Process trajectory data and recognize the digit\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize recognizer\n",
    "        recognizer = TrajectoryRecognizer(model_path)\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(data_file)\n",
    "        \n",
    "        # Preprocess trajectory\n",
    "        grid, tensor_image, preprocessing_data = recognizer.preprocess_trajectory(df)\n",
    "        \n",
    "        # Get prediction\n",
    "        predicted_class, confidence, top3_predictions = recognizer.predict(tensor_image)\n",
    "        \n",
    "        # Visualize complete process\n",
    "        recognizer.visualize_complete_process(df, grid, preprocessing_data,\n",
    "                                           predicted_class, confidence, top3_predictions)\n",
    "        \n",
    "        return predicted_class, confidence, top3_predictions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in recognition process: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../model/mnist_cnn.pth'\n",
    "data_file = '../../data/raw/ft_data_simulated.csv'\n",
    "predicted_digit, confidence, top3 = recognize_trajectory(data_file, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
